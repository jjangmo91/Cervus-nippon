{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9IvWqmFqAlOyW7gdAxbjb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjangmo91/Cervus-nippon/blob/main/Maxent_cns.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 환경 설정 및 라이브러리 임포트"
      ],
      "metadata": {
        "id": "HEYQu16Ug83I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Numpy 버전 2.0 미만 다운그레이드\n",
        "!pip install 'numpy<2.0' -q"
      ],
      "metadata": {
        "id": "uA9H5iVQ0wDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmWpfyjqrsgg"
      },
      "outputs": [],
      "source": [
        "# 필수 패키지 설치\n",
        "!pip install earthengine-api -U -q\n",
        "!pip install eeSDM -q\n",
        "!pip install geemap -U -q\n",
        "!pip install pandas seaborn matplotlib -q\n",
        "!pip install scikit-learn-extra -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 임포트\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import glob\n",
        "import ee\n",
        "import geemap\n",
        "import eeSDM\n",
        "import seaborn as sns\n",
        "\n",
        "import sys\n",
        "import time\n",
        "\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from shapely.geometry import Point\n",
        "from ipyleaflet import WidgetControl\n",
        "from ipywidgets import Label\n",
        "\n",
        "# Earth Engine 인증 및 초기화\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project='ee-jjangmo91')\n",
        "\n",
        "# Google Drive 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_path = '/content/drive/MyDrive/KNPS/Deer/Ecotopia_Data_2024_2025/'"
      ],
      "metadata": {
        "id": "VavnykH_thW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. 데이터 준비 (AOI, 종 출현, 환경 변수)"
      ],
      "metadata": {
        "id": "G1SkEWcLg_bZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 연구지역(AOI) 설정\n",
        "protected_areas = ee.FeatureCollection(\"WCMC/WDPA/current/polygons\")\n",
        "songnisan_park = protected_areas.filter(ee.Filter.eq('WDPAID', 773))\n",
        "aoi = songnisan_park.geometry().buffer(5000) # 공원 경계 5km까지 완충 지역\n",
        "\n",
        "# 종 출현(Occurrence) 데이터 설정\n",
        "base_occurrence_file = '/content/drive/MyDrive/KNPS/Deer/SDM/Data/cervus_nippon_songni.csv'\n",
        "df_occurrence = pd.read_csv(base_occurrence_file)\n",
        "print(f\"  - 종 출현 데이터: '{base_occurrence_file}'에서 {len(df_occurrence)}개 좌표 로드 완료\")\n",
        "\n",
        "# 환경 변수 설정\n",
        "TARGET_SCALE = 30  # 최종 해상도를 30m로 통일\n",
        "TARGET_CRS = 'EPSG:3857' # GEE 표준 좌표계\n",
        "\n",
        "# (1, 2, 3) 고도, 경사, 사면향\n",
        "dem = ee.Image('USGS/SRTMGL1_003')\n",
        "elevation = dem.select('elevation')\n",
        "slope = ee.Terrain.slope(dem)\n",
        "aspect = ee.Terrain.aspect(dem)\n",
        "\n",
        "# (4-8) ESA WorldCover v200 기반 거리 변수 일괄 생성\n",
        "worldcover = ee.ImageCollection('ESA/WorldCover/v200').first().select('Map')\n",
        "dist_to_forest = worldcover.eq(10).fastDistanceTransform().sqrt()   # 10: 산림 (Trees)\n",
        "dist_to_grass = worldcover.eq(30).fastDistanceTransform().sqrt()    # 30: 초지 (Grassland)\n",
        "dist_to_cropland = worldcover.eq(40).fastDistanceTransform().sqrt() # 40: 경작지 (Cropland)\n",
        "dist_to_built = worldcover.eq(50).fastDistanceTransform().sqrt()    # 50: 건물밀집지역 (Built-up)\n",
        "dist_to_water = worldcover.eq(80).fastDistanceTransform().sqrt()    # 80: 수계 (Permanent water bodies)\n",
        "\n",
        "# 모든 변수를 하나의 이미지로 통합\n",
        "predictors = ee.Image.cat([\n",
        "    elevation.rename('elevation'),\n",
        "    slope.rename('slope'),\n",
        "    aspect.rename('aspect'),\n",
        "    dist_to_forest.rename('dist_to_forest'),\n",
        "    dist_to_grass.rename('dist_to_grass'),\n",
        "    dist_to_cropland.rename('dist_to_cropland'),\n",
        "    dist_to_built.rename('dist_to_built'),\n",
        "    dist_to_water.rename('dist_to_water')\n",
        "])\n",
        "\n",
        "# 해상도 및 좌표계 통일 후 AOI에 맞게 자르기\n",
        "predictors = predictors.setDefaultProjection(crs=TARGET_CRS, scale=TARGET_SCALE).clip(aoi)\n",
        "\n",
        "print(f\"  - 환경 변수: 사용자 정의 8종 구축 완료 (해상도: {TARGET_SCALE}m)\")\n",
        "print(f\"  - 구축된 변수: {predictors.bandNames().getInfo()}\")"
      ],
      "metadata": {
        "id": "ZcGiauSYr5OK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aoi = ee.FeatureCollection(\"WCMC/WDPA/current/polygons\") \\\n",
        "        .filter(ee.Filter.eq('WDPAID', 773)) \\\n",
        "        .geometry() \\\n",
        "        .buffer(5000)\n",
        "\n",
        "# ESA WorldCover 이미지 불러오기\n",
        "worldcover = ee.ImageCollection('ESA/WorldCover/v200').first().clip(aoi)\n",
        "\n",
        "# WorldCover 데이터셋의 공식 범례 및 시각화 파라미터 정의\n",
        "worldcover_vis_params = {\n",
        "  \"bands\": [\"Map\"],\n",
        "}\n",
        "worldcover_legend_dict = {\n",
        "    \"Trees\": \"006400\",\n",
        "    \"Shrubland\": \"ffbb22\",\n",
        "    \"Grassland\": \"ffff4c\",\n",
        "    \"Cropland\": \"f096ff\",\n",
        "    \"Built-up\": \"fa0000\",\n",
        "    \"Bare / sparse vegetation\": \"b4b4b4\",\n",
        "    \"Snow and ice\": \"f0f0f0\",\n",
        "    \"Permanent water bodies\": \"0064c8\",\n",
        "    \"Herbaceous wetland\": \"0096a0\",\n",
        "    \"Mangroves\": \"00cf75\",\n",
        "    \"Moss and lichen\": \"fae6a0\",\n",
        "}\n",
        "\n",
        "# 지도 생성 및 레이어 추가\n",
        "m = geemap.Map(center=[36.54, 127.83], zoom=11)\n",
        "m.add_basemap('HYBRID')\n",
        "\n",
        "m.addLayer(worldcover, worldcover_vis_params, 'ESA WorldCover 2020')\n",
        "\n",
        "# add_legend 함수에 'ESA' 템플릿을 명시적으로 지정\n",
        "m.add_legend(\n",
        "    title=\"ESA WorldCover V200\",\n",
        "    legend_dict=worldcover_legend_dict,\n",
        "    position='bottomright',\n",
        "    builtin_legend='ESA'\n",
        ")\n",
        "\n",
        "# 연구지역 경계선 추가\n",
        "m.add_layer(ee.Image().paint(aoi, 0, 2), {'palette': 'yellow'}, 'Area of Interest')\n",
        "m.add_layer_control()\n",
        "\n",
        "display(m)"
      ],
      "metadata": {
        "id": "PYImSNt9CPeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. 다중공선성 분석 및 변수 선택"
      ],
      "metadata": {
        "id": "_LAZ7oZCwKF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install geojson -q\n",
        "\n",
        "try:\n",
        "    # CSV의 실제 위도/경도 컬럼명 지정\n",
        "    LAT_COL = 'latitude'\n",
        "    LON_COL = 'longitude'\n",
        "\n",
        "    # 출현 지점의 환경 변수 값 추출\n",
        "    features = geemap.pandas_to_ee(df_occurrence, latitude_col=LAT_COL, longitude_col=LON_COL)\n",
        "    sampled_points = predictors.sampleRegions(collection=features, scale=TARGET_SCALE, geometries=False)\n",
        "\n",
        "    # GEE 결과를 Pandas 데이터프레임으로 변환\n",
        "    sampled_info = sampled_points.getInfo()\n",
        "    properties_list = [f['properties'] for f in sampled_info['features']]\n",
        "    df_predictors = pd.DataFrame(properties_list)[predictors.bandNames().getInfo()].dropna()\n",
        "    print(\"환경 값 추출 완료.\")\n",
        "\n",
        "    # 2. VIF 및 상관관계 행렬 계산\n",
        "    correlation_matrix = df_predictors.corr()\n",
        "    vif_data = pd.DataFrame()\n",
        "    vif_data[\"feature\"] = df_predictors.columns\n",
        "    vif_data[\"VIF\"] = [variance_inflation_factor(df_predictors.values, i) for i in range(len(df_predictors.columns))]\n",
        "\n",
        "    print(\"\\n[VIF 계산 결과]\")\n",
        "    print(vif_data.to_string(index=False))\n",
        "\n",
        "    # 3. 결과 시각화\n",
        "    vif_sorted = vif_data.set_index('feature').sort_values(by='VIF', ascending=False)\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\n",
        "    fig.suptitle(\"Initial Multicollinearity Analysis (8 Variables)\", fontsize=18)\n",
        "\n",
        "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", ax=ax1, linewidths=.5)\n",
        "    ax1.set_title('Correlation Matrix', fontsize=14)\n",
        "    ax1.tick_params(axis='x', rotation=45)\n",
        "\n",
        "    sns.barplot(x=vif_sorted['VIF'], y=vif_sorted.index, palette='viridis_r', ax=ax2)\n",
        "    ax2.set_title('Variance Inflation Factor (VIF)', fontsize=14)\n",
        "    ax2.set_xlabel('VIF Value'); ax2.set_ylabel('')\n",
        "    ax2.axvline(x=5, color='orange', linestyle='--', label='High Correlation (VIF=5)')\n",
        "    ax2.axvline(x=10, color='red', linestyle='--', label='Very High Correlation (VIF=10)')\n",
        "    ax2.legend()\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "    plt.show()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"분석 중 오류가 발생했습니다: {e}\")"
      ],
      "metadata": {
        "id": "GDIKAedxivj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # 최종 변수 세트 생성\n",
        "    bands_to_remove = ['dist_to_forest', 'dist_to_cropland']\n",
        "    bands_to_keep = predictors.bandNames().removeAll(bands_to_remove)\n",
        "    predictors_final = predictors.select(bands_to_keep)\n",
        "\n",
        "    final_predictor_names = predictors_final.bandNames().getInfo()\n",
        "    print(f\"제거된 변수: {bands_to_remove}\")\n",
        "    print(f\"최종 선택된 변수 ({len(final_predictor_names)}개): {final_predictor_names}\")\n",
        "\n",
        "    # 다중공선성 재검증\n",
        "    # 최종 변수 세트(predictors_final)를 사용하여 환경 값을 다시 추출\n",
        "    features = geemap.pandas_to_ee(df_occurrence, latitude_col='latitude', longitude_col='longitude')\n",
        "    sampled_points_final = predictors_final.sampleRegions(collection=features, scale=TARGET_SCALE, geometries=False)\n",
        "\n",
        "    # GEE 결과를 Pandas 데이터프레임으로 변환\n",
        "    sampled_info_final = sampled_points_final.getInfo()\n",
        "    properties_list_final = [f['properties'] for f in sampled_info_final['features']]\n",
        "    df_predictors_final = pd.DataFrame(properties_list_final)[final_predictor_names].dropna()\n",
        "\n",
        "    # VIF와 상관관계 행렬을 다시 계산\n",
        "    correlation_matrix_final = df_predictors_final.corr()\n",
        "    vif_data_final = pd.DataFrame()\n",
        "    vif_data_final[\"feature\"] = df_predictors_final.columns\n",
        "    vif_data_final[\"VIF\"] = [variance_inflation_factor(df_predictors_final.values, i) for i in range(len(df_predictors_final.columns))]\n",
        "\n",
        "    print(\"\\n[최종 VIF 계산 결과]\")\n",
        "    print(vif_data_final.to_string(index=False))\n",
        "\n",
        "    # 최종 결과 시각화\n",
        "    vif_sorted_final = vif_data_final.set_index('feature').sort_values(by='VIF', ascending=False)\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\n",
        "    fig.suptitle(\"Final Multicollinearity Analysis (6 Variables)\", fontsize=18)\n",
        "\n",
        "    # 상관관계 히트맵\n",
        "    sns.heatmap(correlation_matrix_final, annot=True, cmap='coolwarm', fmt=\".2f\", ax=ax1, linewidths=.5)\n",
        "    ax1.set_title('Final Correlation Matrix', fontsize=14)\n",
        "    ax1.tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # VIF 막대그래프\n",
        "    sns.barplot(x=vif_sorted_final['VIF'], y=vif_sorted_final.index, palette='viridis_r', ax=ax2)\n",
        "    ax2.set_title('Final Variance Inflation Factor (VIF)', fontsize=14)\n",
        "    ax2.set_xlabel('VIF Value'); ax2.set_ylabel('')\n",
        "    ax2.axvline(x=5, color='orange', linestyle='--', label='Threshold (VIF=5)')\n",
        "    ax2.legend()\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "    plt.show()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"분석 중 오류가 발생했습니다: {e}\")"
      ],
      "metadata": {
        "id": "8F9Dh9MRyxvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 최종 선택된 거리 변수들의 통계치 확인\n",
        "print(df_predictors_final[['dist_to_grass', 'dist_to_built', 'dist_to_water']].describe())"
      ],
      "metadata": {
        "id": "FE5k-_C7ITxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시각화를 위한 geemap 지도 객체 생성\n",
        "m = geemap.Map(center=[36.54, 127.83], zoom=11)\n",
        "m.add_basemap('HYBRID')\n",
        "\n",
        "# 각 변수별 시각화 파라미터 정의\n",
        "vis_params = {\n",
        "    'elevation': {'min': 100, 'max': 1500, 'palette': ['#006633', '#E5FFCC', '#662A00', '#D8D8D8', '#F5F5F5']},\n",
        "    'slope': {'min': 0, 'max': 60, 'palette': ['#FFFFFF', '#F0E3A2', '#F1BC67', '#ED7E3A', '#E94423']},\n",
        "    'aspect': {'min': 0, 'max': 360, 'palette': ['#FF0000', '#FFFF00', '#00FF00', '#00FFFF', '#0000FF', '#FF00FF', '#FF0000']},\n",
        "    # 아래 변수들의 max 값을 더 작게 조정하여 세밀한 변화를 확인\n",
        "    'dist_to_grass': {'min': 0, 'max': 50, 'palette': ['#E6E6FA', '#C0C0C0', '#808080']},\n",
        "    'dist_to_built': {'min': 0, 'max': 50, 'palette': ['#FFFFCC', '#FEB24C', '#FD8D3C', '#F03B20', '#BD0026']},\n",
        "    'dist_to_water': {'min': 0, 'max': 150, 'palette': ['#F7FBFF', '#DEEBF7', '#C6DBEF', '#9ECAE1', '#6BAED6']}\n",
        "}\n",
        "\n",
        "# 최종 변수들을 반복문을 통해 지도에 추가\n",
        "for band in predictors_final.bandNames().getInfo():\n",
        "    m.addLayer(\n",
        "        predictors_final.select(band), # 개별 밴드 선택\n",
        "        vis_params[band],              # 해당 밴드의 시각화 파라미터 적용\n",
        "        band,                          # 레이어 이름\n",
        "        True                           # 처음에는 레이어를 켜진 상태로 둠\n",
        "    )\n",
        "\n",
        "# 연구지역 경계선 및 범례 추가\n",
        "m.add_layer(ee.Image().paint(aoi, 0, 2), {'palette': 'yellow'}, 'Area of Interest')\n",
        "m.add_colorbar_branca(colors=vis_params['elevation']['palette'], vmin=vis_params['elevation']['min'], vmax=vis_params['elevation']['max'],\n",
        "                      layer_name='elevation')\n",
        "\n",
        "# 레이어 컨트롤 추가 및 지도 표시\n",
        "m.add_layer_control()\n",
        "display(m)"
      ],
      "metadata": {
        "id": "523kcSQH5Z-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Presence-Background 데이터 생성"
      ],
      "metadata": {
        "id": "ivKlWuWlLM20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Background 포인트 생성 및 환경 값 추출\n",
        "print(\"Background 데이터 생성 및 Google Drive Export를 시작합니다...\")\n",
        "background_points = ee.FeatureCollection.randomPoints(region=aoi, points=5000, seed=0)\n",
        "background_values = predictors_final.sampleRegions(\n",
        "    collection=background_points,\n",
        "    scale=TARGET_SCALE,\n",
        "    geometries=False\n",
        ")\n",
        "\n",
        "# Google Drive로 Export 작업 설정 (최상위 폴더에 저장)\n",
        "EXPORT_FILENAME = 'background_data_cns'\n",
        "\n",
        "task = ee.batch.Export.table.toDrive(\n",
        "    collection=background_values,\n",
        "    description='Export_Background_Points_to_CSV',\n",
        "    folder='',  # <-- 폴더를 비워두어 '내 드라이브' 최상위에 저장\n",
        "    fileNamePrefix=EXPORT_FILENAME,\n",
        "    fileFormat='CSV'\n",
        ")\n",
        "\n",
        "# 작업 시작 및 Colab 내에서 완료 여부 확인\n",
        "task.start()\n",
        "print(f\"\\n작업이 시작되었습니다. (Task ID: {task.id})\")\n",
        "print(f\"'내 드라이브'에 '{EXPORT_FILENAME}.csv' 파일이 생성될 때까지 기다려주세요.\")\n",
        "\n",
        "while task.active():\n",
        "  print('작업 실행 중...')\n",
        "  time.sleep(30)\n",
        "\n",
        "final_status = task.status()['state']\n",
        "if final_status == 'COMPLETED':\n",
        "  print(f\"작업 완료! 이제 다음 셀을 실행하여 파일을 이동하고 로드하세요. (상태: {final_status})\")\n",
        "else:\n",
        "  print(f\"작업이 완료되지 않았습니다. (상태: {final_status})\")\n",
        "  print(f\"오류 메시지: {task.status()['error_message']}\")"
      ],
      "metadata": {
        "id": "fTzognchLijH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 최종 경로에서 Background 데이터 로드\n",
        "BACKGROUND_CSV_PATH = '/content/drive/MyDrive/KNPS/Deer/SDM/Data/background_data_cns.csv'\n",
        "\n",
        "try:\n",
        "    background_df = pd.read_csv(BACKGROUND_CSV_PATH)\n",
        "    if 'system:index' in background_df.columns:\n",
        "        background_df = background_df.drop(columns=['system:index', '.geo'])\n",
        "    print(f\"Google Drive에서 Background 데이터 로드 완료: {len(background_df)}개\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"오류: '{BACKGROUND_CSV_PATH}' 파일을 찾을 수 없습니다.\")\n",
        "    print(\"파일을 정확한 위치로 옮겼는지 확인 후 다시 시도해주세요.\")\n",
        "    sys.exit() # <-- 파일이 없으면 여기서 실행을 중단합니다.\n",
        "\n",
        "\n",
        "# Presence 데이터 환경 값 추출 및 통합\n",
        "features = geemap.pandas_to_ee(df_occurrence, latitude_col='latitude', longitude_col='longitude')\n",
        "presence_values = predictors_final.sampleRegions(collection=features, scale=TARGET_SCALE, geometries=False)\n",
        "presence_info = presence_values.getInfo()\n",
        "properties_list_pr = [f['properties'] for f in presence_info['features']]\n",
        "presence_df = pd.DataFrame(properties_list_pr)\n",
        "\n",
        "background_df.dropna(inplace=True)\n",
        "presence_df.dropna(inplace=True)\n",
        "\n",
        "background_df['pa'] = 0\n",
        "presence_df['pa'] = 1\n",
        "\n",
        "final_modeling_df = pd.concat([presence_df, background_df], ignore_index=True)\n",
        "\n",
        "# 최종 데이터 확인\n",
        "print(f\"\\n최종 Presence-Background 데이터 생성 완료:\")\n",
        "print(f\" - 총 데이터 수: {len(final_modeling_df)} 개\")\n",
        "print(f\" - Presence (pa=1): {len(final_modeling_df[final_modeling_df['pa']==1])} 개\")\n",
        "print(f\" - Background (pa=0): {len(final_modeling_df[final_modeling_df['pa']==0])} 개\")\n",
        "print(\"\\n최종 데이터 샘플:\")\n",
        "display(final_modeling_df.head())"
      ],
      "metadata": {
        "id": "CsGfANIoewc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Spatial Thinning & Spatial Block Corss-Validation"
      ],
      "metadata": {
        "id": "-Mugp5Z3lxZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Spatial Thinning\n",
        "def spatial_thinning(df, distance_m, lat_col='latitude', lon_col='longitude'):\n",
        "    \"\"\"\n",
        "    주어진 거리(m)를 기준으로 종 출현 데이터의 공간 씬닝을 수행\n",
        "\n",
        "    :param df: Pandas 데이터프레임 (위도, 경도 컬럼 포함)\n",
        "    :param distance_m: 최소 허용 거리 (미터 단위)\n",
        "    :param lat_col: 위도 컬럼명\n",
        "    :param lon_col: 경도 컬럼명\n",
        "    :return: 씬닝이 적용된 Pandas 데이터프레임\n",
        "    \"\"\"\n",
        "    # 데이터프레임을 GeoDataFrame으로 변환\n",
        "    gdf = gpd.GeoDataFrame(\n",
        "        df, geometry=gpd.points_from_xy(df[lon_col], df[lat_col]), crs=\"EPSG:4326\"\n",
        "    )\n",
        "    # 미터 단위 계산을 위해 UTM 좌표계로 변환 (한국 중부원점: EPSG:5186)\n",
        "    gdf_proj = gdf.to_crs(\"EPSG:5186\")\n",
        "\n",
        "    # 제거할 포인트의 인덱스를 저장할 집합\n",
        "    to_remove_indices = set()\n",
        "\n",
        "    # 각 포인트에 대해 반복\n",
        "    for index, point in gdf_proj.iterrows():\n",
        "        if index in to_remove_indices:\n",
        "            continue\n",
        "\n",
        "        # 현재 포인트로부터 지정된 거리 내에 있는 다른 포인트들을 찾음\n",
        "        buffer = point.geometry.buffer(distance_m)\n",
        "        nearby_points_indices = gdf_proj.sindex.query(buffer, predicate='intersects')\n",
        "\n",
        "        # 자기 자신을 제외한 인덱스만 필터링\n",
        "        nearby_points_indices = [i for i in nearby_points_indices if i != index]\n",
        "\n",
        "        # 제거할 인덱스에 추가\n",
        "        to_remove_indices.update(nearby_points_indices)\n",
        "\n",
        "    # 제거할 인덱스를 제외하고 최종 데이터프레임 생성\n",
        "    thinned_df = df.drop(index=list(to_remove_indices)).reset_index(drop=True)\n",
        "\n",
        "    return thinned_df\n",
        "\n",
        "# 공간 씬닝 실행\n",
        "THINNING_DISTANCE = 500  # 씬닝 거리: 500m\n",
        "\n",
        "# df_occurrence는 이전에 로드한 원본 출현 데이터\n",
        "df_occurrence_thinned = spatial_thinning(df_occurrence, THINNING_DISTANCE)\n",
        "\n",
        "print(f\"공간 씬닝(Spatial Thinning) 완료 (기준 거리: {THINNING_DISTANCE}m)\")\n",
        "print(f\" - 원본 데이터 수: {len(df_occurrence)} 개\")\n",
        "print(f\" - 씬닝 후 데이터 수: {len(df_occurrence_thinned)} 개\")\n",
        "print(f\" - 제거된 데이터 수: {len(df_occurrence) - len(df_occurrence_thinned)} 개\")\n",
        "\n",
        "# 씬닝 후 데이터 샘플 확인\n",
        "display(df_occurrence_thinned.head())"
      ],
      "metadata": {
        "id": "fDHBSKnDndSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Spatial Block Corss-Validation\n",
        "presence_fc = geemap.pandas_to_ee(df_occurrence_thinned, latitude_col='latitude', longitude_col='longitude')\n",
        "presence_fc = presence_fc.map(lambda ft: ft.set('pa', 1))\n",
        "background_points = ee.FeatureCollection.randomPoints(region=aoi, points=5000, seed=0)\n",
        "background_fc = background_points.map(lambda ft: ft.set('pa', 0))\n",
        "full_fc = presence_fc.merge(background_fc)\n",
        "\n",
        "# 공간 블록 생성\n",
        "scale = 2000  # 2km\n",
        "grid = aoi.coveringGrid(scale=scale, proj='EPSG:4326')\n",
        "\n",
        "# 3. 공간 블록을 훈련(70%) 및 테스트(30%)용으로 임의 분할\n",
        "split = 0.7\n",
        "training_grid = grid.randomColumn(seed=0).filter(ee.Filter.lt('random', split))\n",
        "testing_grid = grid.randomColumn(seed=0).filter(ee.Filter.gte('random', split))\n",
        "\n",
        "# 4. 분할된 블록을 기준으로 훈련/테스트 데이터 세트 생성\n",
        "training_data = full_fc.filter(ee.Filter.bounds(training_grid))\n",
        "testing_data = full_fc.filter(ee.Filter.bounds(testing_grid))\n",
        "\n",
        "# 5. 각 데이터 세트에 환경 변수 값 추출\n",
        "bands = predictors_final.bandNames()\n",
        "training_df = ee.data.computeFeatures({\n",
        "    'expression': predictors_final.sampleRegions(collection=training_data, properties=['pa'], scale=30),\n",
        "    'fileFormat': 'PANDAS_DATAFRAME'\n",
        "})\n",
        "testing_df = ee.data.computeFeatures({\n",
        "    'expression': predictors_final.sampleRegions(collection=testing_data, properties=['pa'], scale=30),\n",
        "    'fileFormat': 'PANDAS_DATAFRAME'\n",
        "})\n",
        "\n",
        "print(\"GEE 기반 공간 분할 및 데이터 준비 완료.\")\n",
        "print(f\" - 훈련 데이터 수: {len(training_df)}\")\n",
        "print(f\" - 테스트 데이터 수: {len(testing_df)}\")\n",
        "\n",
        "# 6. 시각화\n",
        "m = geemap.Map(center=[36.54, 127.83], zoom=11) # 확대 수준 조정\n",
        "m.add_basemap('HYBRID')\n",
        "m.addLayer(training_grid, {'color': 'blue', 'fillColor': 'blue_01'}, 'Training Blocks')\n",
        "m.addLayer(testing_grid, {'color': 'red', 'fillColor': 'red_01'}, 'Testing Blocks')\n",
        "m.addLayer(presence_fc, {'color': 'yellow'}, 'Thinned Presence Points')\n",
        "m.add_layer_control()\n",
        "display(m)"
      ],
      "metadata": {
        "id": "XH_GNyrJpLyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. MaxEnt 하이퍼파라미터 튜닝 및 모델 훈련"
      ],
      "metadata": {
        "id": "XR1hHTGNncUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GEE FeatureCollection을 직접 사용하여 변환 완료\n",
        "training_fc = training_data\n",
        "testing_fc = testing_data\n",
        "\n",
        "print(\"GEE FeatureCollection을 직접 사용하여 변환 완료.\")\n",
        "print(f\" - 훈련 데이터: {training_fc.size().getInfo()} 개\")\n",
        "print(f\" - 테스트 데이터: {testing_fc.size().getInfo()} 개\")"
      ],
      "metadata": {
        "id": "EEadQFDlW6Ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 준비 및 하이퍼파라미터 튜닝 통합\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import ee\n",
        "import geemap\n",
        "\n",
        "print(\"데이터 준비 및 하이퍼파라미터 튜닝을 시작합니다...\")\n",
        "\n",
        "# 'pa' (presence/absence)를 제외한 최종 변수 목록\n",
        "feature_bands = predictors_final.bandNames().getInfo()\n",
        "\n",
        "# 공간 분할된 데이터에 환경 변수 값 추출\n",
        "# training_data와 testing_data에 환경 변수 값을 추가합니다.\n",
        "training_data_with_vars = predictors_final.sampleRegions(\n",
        "    collection=training_data,\n",
        "    properties=['pa'],\n",
        "    scale=30\n",
        ")\n",
        "testing_data_with_vars = predictors_final.sampleRegions(\n",
        "    collection=testing_data,\n",
        "    properties=['pa'],\n",
        "    scale=30\n",
        ")\n",
        "\n",
        "# 데이터 준비 완료 확인\n",
        "print(f\" - 훈련 데이터: {training_data_with_vars.size().getInfo()} 개\")\n",
        "print(f\" - 테스트 데이터: {testing_data_with_vars.size().getInfo()} 개\")\n",
        "\n",
        "# 하이퍼파라미터 튜닝 루프\n",
        "best_auc = -1\n",
        "best_params = {}\n",
        "\n",
        "reg_multipliers = [0.5, 1.0, 1.5, 2.0, 2.5, 3.0]\n",
        "auto_feature_options = [True, False]\n",
        "\n",
        "for multiplier in reg_multipliers:\n",
        "    for auto_feat in auto_feature_options:\n",
        "        try:\n",
        "            maxent_model = ee.Classifier.amnhMaxent(\n",
        "                betaMultiplier=multiplier,\n",
        "                autoFeature=auto_feat\n",
        "            )\n",
        "\n",
        "            trained_model = maxent_model.train(\n",
        "                features=training_data_with_vars,\n",
        "                classProperty='pa',\n",
        "                inputProperties=feature_bands\n",
        "            )\n",
        "\n",
        "            classified_test = testing_data_with_vars.classify(trained_model, 'probability')\n",
        "            predicted_df = geemap.ee_to_df(classified_test)\n",
        "\n",
        "            if predicted_df is not None and not predicted_df.empty:\n",
        "                auc_score = roc_auc_score(predicted_df['pa'], predicted_df['probability'])\n",
        "                print(f\" - 베타 승수: {multiplier}, 자동 특징: {auto_feat}, AUC: {auc_score:.4f}\")\n",
        "\n",
        "                if auc_score > best_auc:\n",
        "                    best_auc = auc_score\n",
        "                    best_params['betaMultiplier'] = multiplier\n",
        "                    best_params['autoFeature'] = auto_feat\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\" - 오류 발생: {e}\")\n",
        "            continue\n",
        "\n",
        "print(\"\\n하이퍼파라미터 튜닝 완료.\")\n",
        "print(f\"최적의 하이퍼파라미터: {best_params}\")\n",
        "print(f\"최고 AUC 점수: {best_auc:.4f}\")\n",
        "\n",
        "if best_params:\n",
        "    best_beta_multiplier = best_params.get('betaMultiplier')\n",
        "    best_auto_feature = best_params.get('autoFeature')\n",
        "else:\n",
        "    best_beta_multiplier = None\n",
        "    best_auto_feature = None"
      ],
      "metadata": {
        "id": "zR87Rh0OhQLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7. 예측 지도 생성"
      ],
      "metadata": {
        "id": "5NuXfK_ltuf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 최적의 하이퍼파라미터로 최종 모델을 생성\n",
        "final_maxent_model = ee.Classifier.amnhMaxent(\n",
        "    betaMultiplier=best_params['betaMultiplier'],\n",
        "    autoFeature=best_params['autoFeature']\n",
        ").train(\n",
        "    features=training_data_with_vars,\n",
        "    classProperty='pa',\n",
        "    inputProperties=feature_bands\n",
        ")\n",
        "\n",
        "# 훈련된 최종 모델로 예측 변수 이미지(predictors) 전체를 분류\n",
        "suitability_map = predictors.classify(final_maxent_model)\n",
        "\n",
        "# 예측 결과 시각화\n",
        "vis_params = {\n",
        "    'min': 0,\n",
        "    'max': 1,\n",
        "    'palette': ['#440154', '#482677', '#404788', '#33638D',\n",
        "                '#287D8E', '#1F968B', '#29AF7F', '#55C667',\n",
        "                '#95D840', '#DCE319']\n",
        "}\n",
        "\n",
        "# 지도 객체를 초기화하고 생성\n",
        "Map = geemap.Map(center=[36.54, 127.83], zoom=11)\n",
        "\n",
        "# 서식지 적합성 지도 레이어 추가\n",
        "Map.addLayer(suitability_map.select('probability'), vis_params, 'Habitat Suitability')\n",
        "Map.add_colorbar(vis_params, label=\"Habitat Suitability\", orientation=\"vertical\", layer_name=\"Habitat Suitability\")\n",
        "\n",
        "# 속리산 국립공원 경계 레이어 추가\n",
        "protected_areas = ee.FeatureCollection(\"WCMC/WDPA/current/polygons\")\n",
        "songnisan_park = protected_areas.filter(ee.Filter.eq('WDPAID', 773))\n",
        "park_boundary_style = {\n",
        "    'color': '000000',\n",
        "    'width': 2,\n",
        "    'fillColor': '00000000'\n",
        "}\n",
        "Map.addLayer(songnisan_park.style(**park_boundary_style), {}, 'Songnisan Park Boundary')\n",
        "\n",
        "# 출현 지점 레이어 추가\n",
        "presence_style = {\n",
        "    'color': 'FF0000', # 빨간색 점\n",
        "    'pointSize': 5\n",
        "}\n",
        "Map.addLayer(presence_fc.style(**presence_style), {}, 'Thinned Presence Points')\n",
        "\n",
        "# 최종 지도를 출력\n",
        "Map"
      ],
      "metadata": {
        "id": "zQCu1reetrvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 잠재적 분포 지도\n",
        "optimal_threshold = 0.6\n",
        "\n",
        "# suitability_map에 임계값을 적용하여 이진 지도\n",
        "potential_distribution_map = suitability_map.gt(optimal_threshold)\n",
        "\n",
        "# 이진 지도를 위한 시각화 팔레트\n",
        "binary_vis_params = {\n",
        "    'min': 0,\n",
        "    'max': 1,\n",
        "    'palette': ['white', 'green'] # 비서식지(흰색), 서식지(초록색)\n",
        "}\n",
        "\n",
        "# 지도 객체를 초기화하고 생성\n",
        "Map = geemap.Map(center=[36.54, 127.83], zoom=11)\n",
        "\n",
        "# 잠재적 분포 지도 레이어만 추가\n",
        "Map.addLayer(potential_distribution_map.select('probability'), binary_vis_params, 'Potential Distribution Map')\n",
        "\n",
        "# 속리산 국립공원 경계 레이어 추가\n",
        "protected_areas = ee.FeatureCollection(\"WCMC/WDPA/current/polygons\")\n",
        "songnisan_park = protected_areas.filter(ee.Filter.eq('WDPAID', 773))\n",
        "park_boundary_style = {\n",
        "    'color': '000000',\n",
        "    'width': 2,\n",
        "    'fillColor': '00000000'\n",
        "}\n",
        "Map.addLayer(songnisan_park.style(**park_boundary_style), {}, 'Songnisan Park Boundary')\n",
        "\n",
        "# 출현 지점 레이어 추가\n",
        "presence_style = {\n",
        "    'color': 'FF0000', # 빨간색 점\n",
        "    'pointSize': 5\n",
        "}\n",
        "Map.addLayer(presence_fc.style(**presence_style), {}, 'Thinned Presence Points')\n",
        "\n",
        "# 지도 레이어 컨트롤 추가 및 출력\n",
        "Map.add_layer_control()\n",
        "Map"
      ],
      "metadata": {
        "id": "wRQevDRmvJ1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8. 모델 적합성 평가"
      ],
      "metadata": {
        "id": "dDakn_8N1J-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 적합성 평가 (TSS, Kappa)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "    # 최적의 임계값(Threshold) 찾기\n",
        "    # Maxent 모델의 기본 최적 임계값은 Maximize sum of sensitivity and specificity를 사용\n",
        "    # 이를 수동으로 찾아 TSS, Kappa를 계산\n",
        "    y_true = predicted_df['pa']\n",
        "    y_pred_proba = predicted_df['probability']\n",
        "\n",
        "    thresholds = np.arange(0, 1, 0.01)\n",
        "    best_threshold = 0\n",
        "    max_tss = -1\n",
        "\n",
        "    for threshold in thresholds:\n",
        "        y_pred_binary = (y_pred_proba > threshold).astype(int)\n",
        "\n",
        "        # sklearn.metrics.confusion_matrix는 True Negative, False Positive, False Negative, True Positive를 반환\n",
        "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred_binary).ravel()\n",
        "\n",
        "        # 민감도(sensitivity)와 특이도(specificity) 계산\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "\n",
        "        # TSS (True Skill Statistic) 계산\n",
        "        tss = sensitivity + specificity - 1\n",
        "\n",
        "        if tss > max_tss:\n",
        "            max_tss = tss\n",
        "            best_threshold = threshold\n",
        "\n",
        "    # 최적 임계값으로 최종 지표 계산\n",
        "    y_pred_binary_final = (y_pred_proba > best_threshold).astype(int)\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred_binary_final).ravel()\n",
        "\n",
        "    # TSS (True Skill Statistic) 계산\n",
        "    sensitivity_final = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    specificity_final = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    tss_final = sensitivity_final + specificity_final - 1\n",
        "\n",
        "    # Kappa 계산\n",
        "    p_o = (tp + tn) / (tp + tn + fp + fn)\n",
        "    p_e = ((tp + fn)*(tp + fp) + (fp + tn)*(fn + tn)) / ((tp + tn + fp + fn)**2)\n",
        "    kappa_final = (p_o - p_e) / (1 - p_e) if p_e < 1 else 0\n",
        "\n",
        "    print(\"\\n[모델 적합성 지표 계산 결과]\")\n",
        "    print(f\" - 최적 임계값: {best_threshold:.4f}\")\n",
        "    print(f\" - TSS (True Skill Statistic): {tss_final:.4f}\")\n",
        "    print(f\" - Kappa: {kappa_final:.4f}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"모델 적합성 평가 중 오류 발생: {e}\")"
      ],
      "metadata": {
        "id": "upua5W7r02Yu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}