{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMt1tUJquHe6wK/gQXVxbh6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjangmo91/Cervus-nippon/blob/main/Cervus_nippon_prep_st.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 환경 설정 및 라이브러리 임포트"
      ],
      "metadata": {
        "id": "HEt-Nc1GNmIO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yhR_0GM2hyQ"
      },
      "outputs": [],
      "source": [
        "# 필수 패키지 설치\n",
        "!pip install eesdm -q\n",
        "!pip install geojson -q\n",
        "!pip install geemap -U -q\n",
        "\n",
        "# 라이브러리 임포트\n",
        "import ee\n",
        "import geemap\n",
        "import pandas as pd\n",
        "import eeSDM\n",
        "from ipyleaflet import WidgetControl\n",
        "from ipywidgets import Label\n",
        "import glob\n",
        "\n",
        "# Earth Engine 인증 및 초기화\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project='ee-jjangmo91')\n",
        "\n",
        "# Google Drive 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_path = '/content/drive/MyDrive/KNPS/Deer/Ecotopia_Data_2024_2025/'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Spatial Thinnging"
      ],
      "metadata": {
        "id": "4Fc2oFpFNr0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 공간 솎아내기(Spatial Thinning) 함수 정의\n",
        "def spatial_thinning(df, resolution_m, lon_col='Longitude', lat_col='Latitude'):\n",
        "    \"\"\"\n",
        "    주어진 해상도(미터 단위)에 따라 격자 기반 공간 솎아내기를 수행합니다.\n",
        "    각 격자 셀 내에서 첫 번째 좌표만 남깁니다.\n",
        "    \"\"\"\n",
        "    if df.empty:\n",
        "        return df\n",
        "\n",
        "    # 1도는 약 111km라는 근사치를 사용하여 미터 해상도를 위경도 단위로 변환\n",
        "    res_deg = resolution_m / 111000\n",
        "\n",
        "    # 각 좌표가 속한 격자의 고유 ID 생성\n",
        "    df['grid_id'] = (df[lat_col] // res_deg).astype(str) + '_' + (df[lon_col] // res_deg).astype(str)\n",
        "\n",
        "    # 각 격자 ID별로 첫 번째 데이터만 남기고 중복 제거\n",
        "    thinned_df = df.drop_duplicates(subset='grid_id', keep='first').copy()\n",
        "\n",
        "    # 임시로 사용한 grid_id 열 삭제 후 반환\n",
        "    return thinned_df.drop(columns=['grid_id'])\n",
        "\n",
        "# 솎아내기 해상도 설정 (단위: 미터)\n",
        "thinning_resolution_meters = 300"
      ],
      "metadata": {
        "id": "2PAmJuU-tXfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 개체별 GPS 파일 목록 불러오기\n",
        "dsf_files = sorted(glob.glob(data_path + 'DSF-*.csv'))\n",
        "dsm_files = sorted(glob.glob(data_path + 'DSM-*.csv'))\n",
        "print(f\"암컷(DSF) 파일 {len(dsf_files)}개, 수컷(DSM) 파일 {len(dsm_files)}개를 발견했습니다.\")\n",
        "\n",
        "# 데이터 통합 함수 정의\n",
        "def combine_gps_data(file_list):\n",
        "    df_list = [pd.read_csv(file) for file in file_list]\n",
        "    return pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "# 성별로 데이터 통합\n",
        "df_female = combine_gps_data(dsf_files)\n",
        "df_male = combine_gps_data(dsm_files)\n",
        "df_all = pd.concat([df_female, df_male], ignore_index=True)\n",
        "\n",
        "# 시간 정보(Collecting_time)를 날짜/시간 형태로 변환\n",
        "for df in [df_female, df_male, df_all]:\n",
        "    df['Collecting_time'] = pd.to_datetime(df['Collecting_time'], errors='coerce')\n",
        "\n",
        "# 분석 그룹(전체, 암컷, 수컷)별로 반복 처리\n",
        "datasets_to_create = {'all': df_all, 'female': df_female, 'male': df_male}\n",
        "\n",
        "for name, df in datasets_to_create.items():\n",
        "    # 전체 기간 데이터에 공간 솎아내기 적용\n",
        "    print(f\"\\n[{name.upper()} 전체 기간] 원본 좌표 수: {len(df):,}\")\n",
        "    df_entire_thinned = spatial_thinning(df.copy(), thinning_resolution_meters)\n",
        "    print(f\"[{name.upper()} 전체 기간] 솎아내기 후 좌표 수: {len(df_entire_thinned):,} ({thinning_resolution_meters}m 해상도)\")\n",
        "\n",
        "    # 솎아낸 전체 기간 데이터셋 저장\n",
        "    sdm_entire = pd.DataFrame({\n",
        "        'longitude': df_entire_thinned['Longitude'],\n",
        "        'latitude': df_entire_thinned['Latitude'],\n",
        "        'cervus': 'cervus-nippon'\n",
        "    })\n",
        "    # 파일 이름에 해상도 정보를 추가하여 구분하기 용이하게 만듭니다.\n",
        "    output_filename_entire = f'sdm_occurrences_{name}_entire_thinned_{thinning_resolution_meters}m.csv'\n",
        "    sdm_entire.to_csv(data_path + output_filename_entire, index=False)\n",
        "    print(f\"   => [{name.upper()} 전체 기간] 솎아낸 좌표 저장 완료.\")\n",
        "\n",
        "    # 겨울철 데이터에 공간 솎아내기 적용\n",
        "    df_winter = df[df['Collecting_time'].dt.month.isin([12, 1, 2])].copy()\n",
        "    if not df_winter.empty:\n",
        "        print(f\"[{name.upper()} 겨울철] 원본 좌표 수: {len(df_winter):,}\")\n",
        "        df_winter_thinned = spatial_thinning(df_winter, thinning_resolution_meters)\n",
        "        print(f\"[{name.upper()} 겨울철] 솎아내기 후 좌표 수: {len(df_winter_thinned):,} ({thinning_resolution_meters}m 해상도)\")\n",
        "\n",
        "        # 솎아낸 겨울철 데이터셋 저장\n",
        "        sdm_winter = pd.DataFrame({\n",
        "            'longitude': df_winter_thinned['Longitude'],\n",
        "            'latitude': df_winter_thinned['Latitude'],\n",
        "            'cervus': 'cervus-nippon'\n",
        "        })\n",
        "        output_filename_winter = f'sdm_occurrences_{name}_winter_thinned_{thinning_resolution_meters}m.csv'\n",
        "        sdm_winter.to_csv(data_path + output_filename_winter, index=False)\n",
        "        print(f\"   => [{name.upper()} 겨울철] 솎아낸 좌표 저장 완료.\")"
      ],
      "metadata": {
        "id": "Ul0EeNCfg5aX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. 전처리된 4개 그룹 데이터 시각화"
      ],
      "metadata": {
        "id": "JMtdDWweNvKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    df_female_entire = pd.read_csv(data_path + f'sdm_occurrences_female_entire_thinned_{thinning_resolution_meters}m.csv')\n",
        "    df_male_entire = pd.read_csv(data_path + f'sdm_occurrences_male_entire_thinned_{thinning_resolution_meters}m.csv')\n",
        "    df_female_winter = pd.read_csv(data_path + f'sdm_occurrences_female_winter_thinned_{thinning_resolution_meters}m.csv')\n",
        "    df_male_winter = pd.read_csv(data_path + f'sdm_occurrences_male_winter_thinned_{thinning_resolution_meters}m.csv')\n",
        "    print(\"Visualization data for 4 thinned groups loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Thinned data files not found. Please ensure the thinning process ran correctly.\")\n",
        "    # 파일이 없는 경우, 이후 코드 실행을 막기 위해 빈 데이터프레임 생성\n",
        "    df_female_entire, df_male_entire, df_female_winter, df_male_winter = [pd.DataFrame(columns=['longitude', 'latitude'])]*4\n",
        "\n",
        "# 속리산 국립공원 경계(AOI) 불러오기 (WDPA ID: 773)\n",
        "protected_areas = ee.FeatureCollection(\"WCMC/WDPA/current/polygons\")\n",
        "aoi = protected_areas.filter(ee.Filter.eq('WDPAID', 773)).geometry()\n",
        "print(\"Songnisan National Park AOI loaded.\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# geemap 호환성을 위해 모든 데이터프레임의 열 이름을 변경\n",
        "for df in [df_female_entire, df_male_entire, df_female_winter, df_male_winter]:\n",
        "    if not df.empty:\n",
        "      df.rename(columns={'x': 'longitude', 'y': 'latitude'}, inplace=True)\n",
        "\n",
        "# pandas 데이터프레임을 ee.FeatureCollection으로 변환\n",
        "ee_f_entire = geemap.pandas_to_ee(df_female_entire)\n",
        "ee_m_entire = geemap.pandas_to_ee(df_male_entire)\n",
        "ee_f_winter = geemap.pandas_to_ee(df_female_winter)\n",
        "ee_m_winter = geemap.pandas_to_ee(df_male_winter)\n",
        "\n",
        "# geemap을 이용한 대화형 지도 생성\n",
        "Map = geemap.Map(center=[36.54, 127.85], zoom=11)\n",
        "\n",
        "# 지도에 레이어 추가\n",
        "Map.addLayer(aoi, {'color': '#006600', 'fillColor': '#33996655'}, 'Songnisan_NP_AOI')\n",
        "Map.addLayer(ee_f_entire, {'color': '#F08080'}, 'Female (Entire) - Thinned')\n",
        "Map.addLayer(ee_m_entire, {'color': '#87CEEB'}, 'Male (Entire) - Thinned')\n",
        "Map.addLayer(ee_f_winter, {'color': '#DC143C'}, 'Female (Winter) - Thinned')\n",
        "Map.addLayer(ee_m_winter, {'color': '#0000CD'}, 'Male (Winter) - Thinned')\n",
        "\n",
        "# 범례(Legend) 추가\n",
        "Map.add_legend(\n",
        "    title=\"Legend (Thinned Data)\",\n",
        "    legend_dict={\n",
        "        f\"Female (Entire)\": \"F08080\",\n",
        "        f\"Male (Entire)\": \"87CEEB\",\n",
        "        f\"Female (Winter)\": \"DC143C\",\n",
        "        f\"Male (Winter)\": \"0000CD\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# 제목 추가\n",
        "title_widget = Label(value=f\"Sika Deer Occurrence ({thinning_resolution_meters}m Thinned)\")\n",
        "Map.add_control(WidgetControl(widget=title_widget, position='topright'))\n",
        "\n",
        "# 지도 출력\n",
        "display(Map)"
      ],
      "metadata": {
        "id": "0NkPnKiQykSG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}