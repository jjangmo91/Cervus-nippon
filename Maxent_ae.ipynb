{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6f2tjtMVryXoWM1WL7PQJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjangmo91/Cervus-nippon/blob/main/Maxent_ae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 환경 설정 및 라이브러리 임포트"
      ],
      "metadata": {
        "id": "HEYQu16Ug83I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Numpy 버전 2.0 미만 다운그레이드\n",
        "!pip install 'numpy<2.0' -q"
      ],
      "metadata": {
        "id": "uA9H5iVQ0wDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmWpfyjqrsgg"
      },
      "outputs": [],
      "source": [
        "# 필수 패키지 설치\n",
        "!pip install earthengine-api -U -q\n",
        "!pip install eeSDM -q\n",
        "!pip install geemap -U -q\n",
        "!pip install pandas seaborn matplotlib -q\n",
        "!pip install scikit-learn-extra -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 임포트\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import ee\n",
        "import geemap\n",
        "import eeSDM\n",
        "import seaborn as sns\n",
        "import sys\n",
        "import time\n",
        "\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from shapely.geometry import Point\n",
        "from ipyleaflet import WidgetControl\n",
        "from ipywidgets import Label\n",
        "\n",
        "# Earth Engine 인증 및 초기화\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project='ee-jjangmo91')\n",
        "\n",
        "# Google Drive 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VavnykH_thW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. 데이터 준비 (AOI, 종 출현, 환경 변수)"
      ],
      "metadata": {
        "id": "G1SkEWcLg_bZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 연구지역(AOI) 설정\n",
        "protected_areas = ee.FeatureCollection(\"WCMC/WDPA/current/polygons\")\n",
        "songnisan_park = protected_areas.filter(ee.Filter.eq('WDPAID', 773))\n",
        "aoi = songnisan_park.geometry().buffer(5000) # 공원 경계 5km까지 완충 지역\n",
        "\n",
        "# 종 출현(Occurrence) 데이터 설정\n",
        "base_occurrence_file = '/content/drive/MyDrive/KNPS/Deer/SDM/Data/sdm_occurrences_all_entire_thinned_300m.csv'\n",
        "df_occurrence = pd.read_csv(base_occurrence_file)\n",
        "print(f\"  - 종 출현 데이터: '{base_occurrence_file}'에서 {len(df_occurrence)}개 좌표 로드 완료\")\n",
        "\n",
        "# 환경 변수 설정\n",
        "TARGET_SCALE = 30  # 최종 해상도를 30m로 통일\n",
        "TARGET_CRS = 'EPSG:3857' # GEE 표준 좌표계\n",
        "\n",
        "# (1, 2, 3) 고도, 경사, 사면향\n",
        "dem = ee.Image('USGS/SRTMGL1_003')\n",
        "elevation = dem.select('elevation')\n",
        "slope = ee.Terrain.slope(dem)\n",
        "aspect = ee.Terrain.aspect(dem)\n",
        "\n",
        "# (4-8) ESA WorldCover v200 기반 거리 변수 일괄 생성\n",
        "worldcover = ee.ImageCollection('ESA/WorldCover/v200').first().select('Map')\n",
        "dist_to_forest = worldcover.eq(10).fastDistanceTransform().sqrt()   # 10: 산림 (Trees)\n",
        "dist_to_grass = worldcover.eq(30).fastDistanceTransform().sqrt()    # 30: 초지 (Grassland)\n",
        "dist_to_cropland = worldcover.eq(40).fastDistanceTransform().sqrt() # 40: 경작지 (Cropland)\n",
        "dist_to_built = worldcover.eq(50).fastDistanceTransform().sqrt()    # 50: 건물밀집지역 (Built-up)\n",
        "dist_to_water = worldcover.eq(80).fastDistanceTransform().sqrt()    # 80: 수계 (Permanent water bodies)\n",
        "\n",
        "# 모든 변수를 하나의 이미지로 통합\n",
        "predictors = ee.Image.cat([\n",
        "    elevation.rename('elevation'),\n",
        "    slope.rename('slope'),\n",
        "    aspect.rename('aspect'),\n",
        "    dist_to_forest.rename('dist_to_forest'),\n",
        "    dist_to_grass.rename('dist_to_grass'),\n",
        "    dist_to_cropland.rename('dist_to_cropland'),\n",
        "    dist_to_built.rename('dist_to_built'),\n",
        "    dist_to_water.rename('dist_to_water')\n",
        "])\n",
        "\n",
        "# 해상도 및 좌표계 통일 후 AOI에 맞게 자르기\n",
        "predictors = predictors.setDefaultProjection(crs=TARGET_CRS, scale=TARGET_SCALE).clip(aoi)\n",
        "\n",
        "print(f\"  - 환경 변수: 사용자 정의 8종 구축 완료 (해상도: {TARGET_SCALE}m)\")\n",
        "print(f\"  - 구축된 변수: {predictors.bandNames().getInfo()}\")"
      ],
      "metadata": {
        "id": "ZcGiauSYr5OK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 연구 대상 지역(AOI) 설정\n",
        "aoi = ee.FeatureCollection(\"WCMC/WDPA/current/polygons\") \\\n",
        "        .filter(ee.Filter.eq('WDPAID', 773)) \\\n",
        "        .geometry() \\\n",
        "        .buffer(5000)\n",
        "\n",
        "# ESA WorldCover 이미지 불러오기\n",
        "worldcover = ee.ImageCollection('ESA/WorldCover/v200').first().clip(aoi)\n",
        "\n",
        "# WorldCover 데이터셋의 공식 범례 정의\n",
        "worldcover_legend_dict = {\n",
        "    \"Trees\": \"006400\", \"Shrubland\": \"ffbb22\", \"Grassland\": \"ffff4c\",\n",
        "    \"Cropland\": \"f096ff\", \"Built-up\": \"fa0000\", \"Bare / sparse vegetation\": \"b4b4b4\",\n",
        "    \"Snow and ice\": \"f0f0f0\", \"Permanent water bodies\": \"0064c8\",\n",
        "    \"Herbaceous wetland\": \"0096a0\", \"Mangroves\": \"00cf75\", \"Moss and lichen\": \"fae6a0\",\n",
        "}\n",
        "\n",
        "# 시각화 파라미터에 직접 정의한 딕셔너리의 색상 팔레트를 추가합니다.\n",
        "worldcover_vis_params = {\n",
        "  \"bands\": [\"Map\"],\n",
        "  \"palette\": list(worldcover_legend_dict.values())\n",
        "}\n",
        "\n",
        "# 지도 생성 및 레이어 추가\n",
        "m = geemap.Map(center=[36.54, 127.83], zoom=11)\n",
        "m.add_basemap('HYBRID')\n",
        "\n",
        "m.addLayer(worldcover, worldcover_vis_params, 'ESA WorldCover 2021')\n",
        "\n",
        "# legend_dict를 사용\n",
        "m.add_legend(\n",
        "    title=\"ESA WorldCover V200\",\n",
        "    legend_dict=worldcover_legend_dict,\n",
        "    position='bottomright'\n",
        ")\n",
        "\n",
        "# 연구지역 경계선 추가\n",
        "m.addLayer(ee.Image().paint(aoi, 0, 2), {'palette': 'yellow'}, 'Area of Interest')\n",
        "\n",
        "display(m)"
      ],
      "metadata": {
        "id": "PYImSNt9CPeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. 다중공선성 분석 및 변수 선택"
      ],
      "metadata": {
        "id": "_LAZ7oZCwKF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install geojson -q\n",
        "\n",
        "try:\n",
        "    # CSV의 실제 위도/경도 컬럼명 지정\n",
        "    LAT_COL = 'latitude'\n",
        "    LON_COL = 'longitude'\n",
        "\n",
        "    # 출현 지점의 환경 변수 값 추출\n",
        "    features = geemap.pandas_to_ee(df_occurrence, latitude_col=LAT_COL, longitude_col=LON_COL)\n",
        "    sampled_points = predictors.sampleRegions(collection=features, scale=TARGET_SCALE, geometries=False)\n",
        "\n",
        "    # GEE 결과를 Pandas 데이터프레임으로 변환\n",
        "    sampled_info = sampled_points.getInfo()\n",
        "    properties_list = [f['properties'] for f in sampled_info['features']]\n",
        "    df_predictors = pd.DataFrame(properties_list)[predictors.bandNames().getInfo()].dropna()\n",
        "    print(\"환경 값 추출 완료.\")\n",
        "\n",
        "    # 2. VIF 및 상관관계 행렬 계산\n",
        "    correlation_matrix = df_predictors.corr()\n",
        "    vif_data = pd.DataFrame()\n",
        "    vif_data[\"feature\"] = df_predictors.columns\n",
        "    vif_data[\"VIF\"] = [variance_inflation_factor(df_predictors.values, i) for i in range(len(df_predictors.columns))]\n",
        "\n",
        "    print(\"\\n[VIF 계산 결과]\")\n",
        "    print(vif_data.to_string(index=False))\n",
        "\n",
        "    # 3. 결과 시각화\n",
        "    vif_sorted = vif_data.set_index('feature').sort_values(by='VIF', ascending=False)\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\n",
        "    fig.suptitle(\"Initial Multicollinearity Analysis (8 Variables)\", fontsize=18)\n",
        "\n",
        "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", ax=ax1, linewidths=.5)\n",
        "    ax1.set_title('Correlation Matrix', fontsize=14)\n",
        "    ax1.tick_params(axis='x', rotation=45)\n",
        "\n",
        "    sns.barplot(x=vif_sorted['VIF'], y=vif_sorted.index, palette='viridis_r', ax=ax2)\n",
        "    ax2.set_title('Variance Inflation Factor (VIF)', fontsize=14)\n",
        "    ax2.set_xlabel('VIF Value'); ax2.set_ylabel('')\n",
        "    ax2.axvline(x=5, color='orange', linestyle='--', label='High Correlation (VIF=5)')\n",
        "    ax2.axvline(x=10, color='red', linestyle='--', label='Very High Correlation (VIF=10)')\n",
        "    ax2.legend()\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "    plt.show()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"분석 중 오류가 발생했습니다: {e}\")"
      ],
      "metadata": {
        "id": "GDIKAedxivj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # 최종 변수 세트 생성\n",
        "    bands_to_remove = ['dist_to_forest', 'dist_to_cropland']\n",
        "    bands_to_keep = predictors.bandNames().removeAll(bands_to_remove)\n",
        "    predictors_final = predictors.select(bands_to_keep)\n",
        "\n",
        "    final_predictor_names = predictors_final.bandNames().getInfo()\n",
        "    print(f\"제거된 변수: {bands_to_remove}\")\n",
        "    print(f\"최종 선택된 변수 ({len(final_predictor_names)}개): {final_predictor_names}\")\n",
        "\n",
        "    # 다중공선성 재검증\n",
        "    # 최종 변수 세트(predictors_final)를 사용하여 환경 값을 다시 추출\n",
        "    features = geemap.pandas_to_ee(df_occurrence, latitude_col='latitude', longitude_col='longitude')\n",
        "    sampled_points_final = predictors_final.sampleRegions(collection=features, scale=TARGET_SCALE, geometries=False)\n",
        "\n",
        "    # GEE 결과를 Pandas 데이터프레임으로 변환\n",
        "    sampled_info_final = sampled_points_final.getInfo()\n",
        "    properties_list_final = [f['properties'] for f in sampled_info_final['features']]\n",
        "    df_predictors_final = pd.DataFrame(properties_list_final)[final_predictor_names].dropna()\n",
        "\n",
        "    # VIF와 상관관계 행렬을 다시 계산\n",
        "    correlation_matrix_final = df_predictors_final.corr()\n",
        "    vif_data_final = pd.DataFrame()\n",
        "    vif_data_final[\"feature\"] = df_predictors_final.columns\n",
        "    vif_data_final[\"VIF\"] = [variance_inflation_factor(df_predictors_final.values, i) for i in range(len(df_predictors_final.columns))]\n",
        "\n",
        "    print(\"\\n[최종 VIF 계산 결과]\")\n",
        "    print(vif_data_final.to_string(index=False))\n",
        "\n",
        "    # 최종 결과 시각화\n",
        "    vif_sorted_final = vif_data_final.set_index('feature').sort_values(by='VIF', ascending=False)\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\n",
        "    fig.suptitle(\"Final Multicollinearity Analysis (6 Variables)\", fontsize=18)\n",
        "\n",
        "    # 상관관계 히트맵\n",
        "    sns.heatmap(correlation_matrix_final, annot=True, cmap='coolwarm', fmt=\".2f\", ax=ax1, linewidths=.5)\n",
        "    ax1.set_title('Final Correlation Matrix', fontsize=14)\n",
        "    ax1.tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # VIF 막대그래프\n",
        "    sns.barplot(x=vif_sorted_final['VIF'], y=vif_sorted_final.index, palette='viridis_r', ax=ax2)\n",
        "    ax2.set_title('Final Variance Inflation Factor (VIF)', fontsize=14)\n",
        "    ax2.set_xlabel('VIF Value'); ax2.set_ylabel('')\n",
        "    ax2.axvline(x=5, color='orange', linestyle='--', label='Threshold (VIF=5)')\n",
        "    ax2.legend()\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "    plt.show()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"분석 중 오류가 발생했습니다: {e}\")"
      ],
      "metadata": {
        "id": "8F9Dh9MRyxvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 최종 선택된 거리 변수들의 통계치 확인\n",
        "print(df_predictors_final[['dist_to_grass', 'dist_to_built', 'dist_to_water']].describe())"
      ],
      "metadata": {
        "id": "FE5k-_C7ITxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시각화를 위한 geemap 지도 객체 생성\n",
        "m = geemap.Map(center=[36.54, 127.83], zoom=11)\n",
        "m.add_basemap('HYBRID')\n",
        "\n",
        "# 각 변수별 시각화 파라미터 정의\n",
        "vis_params = {\n",
        "    'elevation': {'min': 100, 'max': 1500, 'palette': ['#006633', '#E5FFCC', '#662A00', '#D8D8D8', '#F5F5F5']},\n",
        "    'slope': {'min': 0, 'max': 60, 'palette': ['#FFFFFF', '#F0E3A2', '#F1BC67', '#ED7E3A', '#E94423']},\n",
        "    'aspect': {'min': 0, 'max': 360, 'palette': ['#FF0000', '#FFFF00', '#00FF00', '#00FFFF', '#0000FF', '#FF00FF', '#FF0000']},\n",
        "    # 아래 변수들의 max 값을 더 작게 조정하여 세밀한 변화를 확인\n",
        "    'dist_to_grass': {'min': 0, 'max': 50, 'palette': ['#E6E6FA', '#C0C0C0', '#808080']},\n",
        "    'dist_to_built': {'min': 0, 'max': 50, 'palette': ['#FFFFCC', '#FEB24C', '#FD8D3C', '#F03B20', '#BD0026']},\n",
        "    'dist_to_water': {'min': 0, 'max': 150, 'palette': ['#F7FBFF', '#DEEBF7', '#C6DBEF', '#9ECAE1', '#6BAED6']}\n",
        "}\n",
        "\n",
        "# 최종 변수들을 반복문을 통해 지도에 추가\n",
        "for band in predictors_final.bandNames().getInfo():\n",
        "    m.addLayer(\n",
        "        predictors_final.select(band), # 개별 밴드 선택\n",
        "        vis_params[band],              # 해당 밴드의 시각화 파라미터 적용\n",
        "        band,                          # 레이어 이름\n",
        "        True                           # 처음에는 레이어를 켜진 상태로 둠\n",
        "    )\n",
        "\n",
        "# 연구지역 경계선 및 범례 추가\n",
        "m.add_layer(ee.Image().paint(aoi, 0, 2), {'palette': 'yellow'}, 'Area of Interest')\n",
        "m.add_colorbar_branca(colors=vis_params['elevation']['palette'], vmin=vis_params['elevation']['min'], vmax=vis_params['elevation']['max'],\n",
        "                      layer_name='elevation')\n",
        "\n",
        "# 레이어 컨트롤 추가 및 지도 표시\n",
        "m.add_layer_control()\n",
        "display(m)"
      ],
      "metadata": {
        "id": "523kcSQH5Z-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Presence-Background 데이터 생성"
      ],
      "metadata": {
        "id": "ivKlWuWlLM20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 예측 변수에 데이터가 있는 유효 영역 마스크 생성\n",
        "valid_data_mask = predictors_final.reduce(ee.Reducer.allNonZero()).selfMask()\n",
        "\n",
        "# 유효 영역 내에서만 Background 포인트 생성\n",
        "print(\"유효 데이터 영역 내에서 Background 데이터 생성을 시작합니다...\")\n",
        "try:\n",
        "    background_points = valid_data_mask.stratifiedSample(\n",
        "        numPoints=5000,\n",
        "        region=aoi,\n",
        "        scale=TARGET_SCALE,\n",
        "        seed=0,\n",
        "        geometries=True\n",
        "    )\n",
        "\n",
        "    # 생성된 background_points의 좌표를 먼저 추출하여 Pandas DataFrame으로 변환\n",
        "    coords = background_points.geometry().coordinates().getInfo()\n",
        "    coords_df = pd.DataFrame(coords, columns=['longitude', 'latitude'])\n",
        "\n",
        "    # 환경 변수 값 추출 (geometries=False는 그대로 유지하여 효율적으로 값만 가져옴)\n",
        "    background_values = predictors_final.sampleRegions(\n",
        "        collection=background_points,\n",
        "        scale=TARGET_SCALE,\n",
        "        geometries=False\n",
        "    )\n",
        "\n",
        "    # .getInfo()를 사용하여 환경 변수 값을 DataFrame으로 가져오기\n",
        "    background_info = background_values.getInfo()\n",
        "    properties_list_bg = [f['properties'] for f in background_info['features']]\n",
        "    env_vars_df = pd.DataFrame(properties_list_bg)\n",
        "\n",
        "    # 좌표 DataFrame(coords_df)과 환경 변수 DataFrame(env_vars_df)을 합치기\n",
        "    background_df = pd.concat([coords_df, env_vars_df], axis=1)\n",
        "\n",
        "    if 'system:index' in background_df.columns:\n",
        "        background_df = background_df.drop(columns=['system:index'])\n",
        "\n",
        "    print(f\"Background 데이터 추출 및 변환 완료: {len(background_df)}개\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Background 데이터 처리 중 오류 발생: {e}\")\n",
        "    sys.exit()\n",
        "\n",
        "# Presence 데이터 환경 값 추출 및 통합\n",
        "print(\"\\nPresence 데이터 추출을 시작합니다...\")\n",
        "features = geemap.pandas_to_ee(df_occurrence, latitude_col='latitude', longitude_col='longitude')\n",
        "presence_values = predictors_final.sampleRegions(collection=features, scale=TARGET_SCALE, geometries=False)\n",
        "presence_info = presence_values.getInfo()\n",
        "properties_list_pr = [f['properties'] for f in presence_info['features']]\n",
        "presence_df = pd.DataFrame(properties_list_pr)\n",
        "print(f\"Presence 데이터 추출 완료: {len(presence_df)}개\")\n",
        "\n",
        "# 결측치 제거\n",
        "background_df.dropna(inplace=True)\n",
        "presence_df.dropna(inplace=True)\n",
        "\n",
        "# pa 컬럼 추가 및 병합\n",
        "background_df['pa'] = 0\n",
        "presence_df['pa'] = 1\n",
        "final_modeling_df = pd.concat([presence_df, background_df], ignore_index=True)\n",
        "\n",
        "# 최종 데이터 확인\n",
        "print(f\"\\n최종 Presence-Background 데이터 생성 완료:\")\n",
        "print(f\" - 총 데이터 수: {len(final_modeling_df)} 개\")\n",
        "print(f\" - Presence (pa=1): {len(final_modeling_df[final_modeling_df['pa']==1])} 개\")\n",
        "print(f\" - Background (pa=0): {len(final_modeling_df[final_modeling_df['pa']==0])} 개\")\n",
        "print(\"\\n최종 데이터 샘플:\")\n",
        "display(final_modeling_df.head())\n",
        "\n",
        "# 최종 모델링 데이터를 드라이브에 저장\n",
        "SAVE_PATH = '/content/drive/MyDrive/KNPS/Deer/SDM/Data/final_modeling_data_ae.csv'\n",
        "final_modeling_df.to_csv(SAVE_PATH, index=False)\n",
        "print(f\"\\n최종 모델링 데이터가 다음 경로에 저장되었습니다: {SAVE_PATH}\")"
      ],
      "metadata": {
        "id": "jAb9BA-l3423"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Spatial Block Corss-Validation"
      ],
      "metadata": {
        "id": "-Mugp5Z3lxZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"GEE 업로드용 데이터프레임을 정제합니다...\")\n",
        "df_for_gee = final_modeling_df[['longitude', 'latitude', 'pa']].copy()\n",
        "print(\"정제 완료.\")\n",
        "\n",
        "# GEE에서 공간 블록 생성\n",
        "print(\"\\nGEE에서 훈련/테스트용 공간 블록을 생성합니다...\")\n",
        "scale = 2000\n",
        "grid = aoi.coveringGrid(scale=scale, proj='EPSG:4326')\n",
        "split = 0.7\n",
        "training_grid_ee = grid.randomColumn(seed=0).filter(ee.Filter.lt('random', split))\n",
        "testing_grid_ee = grid.randomColumn(seed=0).filter(ee.Filter.gte('random', split))\n",
        "print(\"공간 블록 생성이 완료되었습니다.\")\n",
        "\n",
        "# 정제된 포인트를 GEE FeatureCollection으로 준비\n",
        "presence_df_for_ee = df_for_gee[df_for_gee['pa'] == 1]\n",
        "presence_fc = geemap.pandas_to_ee(presence_df_for_ee, latitude_col='latitude', longitude_col='longitude')\n",
        "presence_fc = presence_fc.map(lambda ft: ft.set('pa', 1))\n",
        "\n",
        "background_df_for_ee = df_for_gee[df_for_gee['pa'] == 0]\n",
        "background_fc = geemap.pandas_to_ee(background_df_for_ee, latitude_col='latitude', longitude_col='longitude')\n",
        "background_fc = background_fc.map(lambda ft: ft.set('pa', 0))\n",
        "\n",
        "full_fc = presence_fc.merge(background_fc)\n",
        "\n",
        "# 모든 포인트에 좌표 정보를 속성(property)으로 추가\n",
        "def add_coords(feat):\n",
        "    coords = feat.geometry().coordinates()\n",
        "    return feat.set('longitude', coords.get(0), 'latitude', coords.get(1))\n",
        "\n",
        "full_fc_with_coords = full_fc.map(add_coords)\n",
        "\n",
        "# GEE 서버 내에서 공간 분할 및 환경 변수 값 추출\n",
        "print(\"\\nGEE 서버에서 공간 분할 및 데이터 샘플링을 수행합니다...\")\n",
        "training_data_ee = full_fc_with_coords.filter(ee.Filter.bounds(training_grid_ee))\n",
        "testing_data_ee = full_fc_with_coords.filter(ee.Filter.bounds(testing_grid_ee))\n",
        "\n",
        "# sampleRegions의 properties 목록에 'longitude', 'latitude'를 추가하여 최종 결과에 좌표 정보가 포함\n",
        "training_df = ee.data.computeFeatures({\n",
        "    'expression': predictors_final.sampleRegions(collection=training_data_ee, properties=['pa', 'longitude', 'latitude'], scale=TARGET_SCALE),\n",
        "    'fileFormat': 'PANDAS_DATAFRAME'\n",
        "})\n",
        "\n",
        "testing_df = ee.data.computeFeatures({\n",
        "    'expression': predictors_final.sampleRegions(collection=testing_data_ee, properties=['pa', 'longitude', 'latitude'], scale=TARGET_SCALE),\n",
        "    'fileFormat': 'PANDAS_DATAFRAME'\n",
        "})\n",
        "\n",
        "print(\"GEE 기반 공간 분할 및 데이터 준비가 완료되었습니다.\")\n",
        "print(f\" - 훈련 데이터 수: {len(training_df)}\")\n",
        "print(f\" - 테스트 데이터 수: {len(testing_df)}\")\n",
        "print(\"\\n생성된 훈련 데이터프레임 샘플:\")\n",
        "display(training_df.head()) # .head()를 통해 좌표 컬럼이 있는지 확인\n",
        "\n",
        "# 시각화 (기존과 동일)\n",
        "print(\"\\n분할 결과를 시각화합니다...\")\n",
        "m = geemap.Map(center=[36.54, 127.83], zoom=11)\n",
        "m.add_basemap('HYBRID')\n",
        "\n",
        "m.addLayer(training_grid_ee, {'color': 'blue', 'fillColor': 'rgba(0, 0, 255, 0.1)'}, 'Training Blocks')\n",
        "m.addLayer(testing_grid_ee, {'color': 'red', 'fillColor': 'rgba(255, 0, 0, 0.1)'}, 'Testing Blocks')\n",
        "m.addLayer(presence_fc, {'color': 'yellow'}, 'Presence Points')\n",
        "\n",
        "m.add_layer_control()\n",
        "display(m)"
      ],
      "metadata": {
        "id": "NbMN09DD_9wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. MaxEnt 하이퍼파라미터 튜닝 및 모델 훈련"
      ],
      "metadata": {
        "id": "XR1hHTGNncUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "import ee\n",
        "import geemap\n",
        "\n",
        "print(\"데이터 준비 및 하이퍼파라미터 튜닝을 시작합니다...\")\n",
        "\n",
        "# 1. 이전 단계에서 생성된 Pandas 데이터프레임(training_df, testing_df)을\n",
        "#    GEE FeatureCollection으로 변환합니다.\n",
        "try:\n",
        "    training_fc = geemap.pandas_to_ee(training_df, latitude_col='latitude', longitude_col='longitude')\n",
        "    testing_fc = geemap.pandas_to_ee(testing_df, latitude_col='latitude', longitude_col='longitude')\n",
        "    print(\"Pandas 데이터프레임을 GEE FeatureCollection으로 변환 완료.\")\n",
        "    print(f\" - 훈련 데이터: {training_fc.size().getInfo()} 개\")\n",
        "    print(f\" - 테스트 데이터: {testing_fc.size().getInfo()} 개\")\n",
        "except Exception as e:\n",
        "    print(f\"데이터 변환 중 오류 발생: {e}\")\n",
        "    # 이 단계에서 오류가 발생하면, 이전 셀의 training_df와 testing_df가 올바른지 확인해야 합니다.\n",
        "\n",
        "# 2. 하이퍼파라미터 튜닝\n",
        "# 'pa' (presence/absence)를 제외한 최종 변수 목록\n",
        "feature_bands = predictors_final.bandNames().getInfo()\n",
        "\n",
        "best_auc = -1\n",
        "best_params = {}\n",
        "tuning_results = [] # 결과를 저장할 리스트\n",
        "\n",
        "reg_multipliers = [0.5, 1.0, 1.5, 2.0, 2.5, 3.0]\n",
        "auto_feature_options = [True, False]\n",
        "\n",
        "print(\"\\n하이퍼파라미터 튜닝 루프를 시작합니다...\")\n",
        "for multiplier in reg_multipliers:\n",
        "    for auto_feat in auto_feature_options:\n",
        "        try:\n",
        "            # Maxent 모델 정의\n",
        "            maxent_model = ee.Classifier.amnhMaxent(\n",
        "                betaMultiplier=multiplier,\n",
        "                autoFeature=auto_feat\n",
        "            )\n",
        "\n",
        "            # 모델 훈련 (변환된 training_fc 사용)\n",
        "            trained_model = maxent_model.train(\n",
        "                features=training_fc,\n",
        "                classProperty='pa',\n",
        "                inputProperties=feature_bands\n",
        "            )\n",
        "\n",
        "            # 테스트 데이터로 예측 (변환된 testing_fc 사용)\n",
        "            classified_test = testing_fc.classify(trained_model, 'probability')\n",
        "\n",
        "            # GEE 결과를 Pandas 데이터프레임으로 가져와 AUC 계산\n",
        "            predicted_df = geemap.ee_to_df(classified_test)\n",
        "\n",
        "            if predicted_df is not None and not predicted_df.empty:\n",
        "                # 'pa' 컬럼의 데이터 타입을 일치시켜줍니다 (예: 정수형)\n",
        "                true_labels = predicted_df['pa'].astype(int)\n",
        "                pred_scores = predicted_df['probability']\n",
        "\n",
        "                # 라벨에 하나의 클래스만 있는지 확인\n",
        "                if len(true_labels.unique()) < 2:\n",
        "                    print(f\" - 베타 승수: {multiplier}, 자동 특징: {auto_feat}, AUC: 계산 불가 (테스트 데이터에 하나의 클래스만 존재)\")\n",
        "                    continue\n",
        "\n",
        "                auc_score = roc_auc_score(true_labels, pred_scores)\n",
        "                result_str = f\" - 베타 승수: {multiplier}, 자동 특징: {auto_feat}, AUC: {auc_score:.4f}\"\n",
        "                print(result_str)\n",
        "                tuning_results.append(result_str)\n",
        "\n",
        "                # 최고 성능 모델 업데이트\n",
        "                if auc_score > best_auc:\n",
        "                    best_auc = auc_score\n",
        "                    best_params['betaMultiplier'] = multiplier\n",
        "                    best_params['autoFeature'] = auto_feat\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\" - 베타 승수: {multiplier}, 자동 특징: {auto_feat}, 오류 발생: {e}\")\n",
        "            continue\n",
        "\n",
        "print(\"\\n--- 하이퍼파라미터 튜닝 완료 ---\")\n",
        "if best_params:\n",
        "    print(f\"최적의 하이퍼파라미터: {best_params}\")\n",
        "    print(f\"최고 AUC 점수: {best_auc:.4f}\")\n",
        "\n",
        "    # 찾은 최적의 파라미터로 최종 모델 훈련\n",
        "    print(\"\\n최적의 파라미터로 최종 모델을 훈련합니다...\")\n",
        "    final_model = ee.Classifier.amnhMaxent(**best_params).train(\n",
        "        features=training_fc,\n",
        "        classProperty='pa',\n",
        "        inputProperties=feature_bands\n",
        "    )\n",
        "    print(\"최종 모델 훈련 완료.\")\n",
        "else:\n",
        "    print(\"최적의 하이퍼파라미터를 찾지 못했습니다. 오류 메시지를 확인해주세요.\")"
      ],
      "metadata": {
        "id": "zR87Rh0OhQLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7. 모델 적합성 평가"
      ],
      "metadata": {
        "id": "uqy23jNFMU-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
        "\n",
        "# 테스트 데이터에 대한 예측 수행\n",
        "print(\"최종 모델을 사용하여 테스트 데이터셋의 예측 확률을 계산합니다...\")\n",
        "try:\n",
        "    classified_test_final = testing_fc.classify(final_model, 'probability')\n",
        "    predicted_df = geemap.ee_to_df(classified_test_final)\n",
        "    predicted_df['pa'] = predicted_df['pa'].astype(int)\n",
        "    predicted_df['probability'] = predicted_df['probability'].astype(float)\n",
        "    print(\"예측 완료.\")\n",
        "except Exception as e:\n",
        "    print(f\"테스트 데이터 예측 중 오류 발생: {e}\")\n",
        "\n",
        "# 필요한 변수들을 미리 정의\n",
        "true_labels = predicted_df['pa']\n",
        "pred_scores = predicted_df['probability']\n",
        "\n",
        "\n",
        "# AUC 점수 계산\n",
        "print(\"\\n--- AUC 점수 ---\")\n",
        "auc_score = roc_auc_score(true_labels, pred_scores)\n",
        "print(f\"AUC (Area Under the Curve): {auc_score:.4f}\")\n",
        "\n",
        "\n",
        "# 최적의 임계값(Threshold) 및 TSS 찾기\n",
        "print(\"\\n최적의 임계값을 찾기 위해 TSS를 계산합니다...\")\n",
        "thresholds = np.linspace(0.0, 1.0, 101)\n",
        "tss_scores = []\n",
        "sensitivity_scores = []\n",
        "specificity_scores = []\n",
        "\n",
        "for t in thresholds:\n",
        "    pred_labels = (pred_scores >= t).astype(int)\n",
        "    tn, fp, fn, tp = confusion_matrix(true_labels, pred_labels).ravel()\n",
        "\n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "\n",
        "    tss = sensitivity + specificity - 1\n",
        "    tss_scores.append(tss)\n",
        "    sensitivity_scores.append(sensitivity)\n",
        "    specificity_scores.append(specificity)\n",
        "\n",
        "max_tss_index = np.argmax(tss_scores)\n",
        "optimal_threshold = thresholds[max_tss_index]\n",
        "max_tss = tss_scores[max_tss_index]\n",
        "\n",
        "print(f\"\\n--- 최적 임계값 및 주요 지표 ---\")\n",
        "print(f\"TSS를 최대로 만드는 최적 임계값: {optimal_threshold:.4f}\")\n",
        "print(f\"최대 TSS (True Skill Statistic): {max_tss:.4f}\")\n",
        "print(f\" - 해당 임계값에서의 민감도(Sensitivity): {sensitivity_scores[max_tss_index]:.4f}\")\n",
        "print(f\" - 해당 임계값에서의 특이도(Specificity): {specificity_scores[max_tss_index]:.4f}\")\n",
        "\n",
        "\n",
        "# ROC 곡선 및 기타 지표 시각화\n",
        "print(\"\\n평가 지표를 시각화합니다...\")\n",
        "fpr, tpr, _ = roc_curve(true_labels, pred_scores)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n",
        "\n",
        "# 첫 번째 그래프: ROC Curve\n",
        "ax1.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {auc_score:.4f})')\n",
        "ax1.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "ax1.set_xlim([0.0, 1.0])\n",
        "ax1.set_ylim([0.0, 1.05])\n",
        "ax1.set_xlabel('False Positive Rate (1 - Specificity)', fontsize=12)\n",
        "ax1.set_ylabel('True Positive Rate (Sensitivity)', fontsize=12)\n",
        "ax1.set_title('Receiver Operating Characteristic (ROC) Curve', fontsize=16)\n",
        "ax1.legend(loc=\"lower right\")\n",
        "ax1.grid(True)\n",
        "\n",
        "# 두 번째 그래프: Metrics vs. Threshold\n",
        "ax2.plot(thresholds, tss_scores, label='TSS', color='blue', lw=2)\n",
        "ax2.plot(thresholds, sensitivity_scores, label='Sensitivity', color='green', linestyle='--')\n",
        "ax2.plot(thresholds, specificity_scores, label='Specificity', color='red', linestyle='--')\n",
        "ax2.axvline(optimal_threshold, color='purple', linestyle=':', label=f'Optimal Threshold ({optimal_threshold:.2f})')\n",
        "ax2.set_title('Metrics vs. Threshold', fontsize=16)\n",
        "ax2.set_xlabel('Threshold', fontsize=12)\n",
        "ax2.set_ylabel('Score', fontsize=12)\n",
        "ax2.legend()\n",
        "ax2.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j-5jnIP5MW1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 데이터에서 각 변수의 평균값 계산\n",
        "print(\"반응 곡선 생성을 위해 변수별 평균값을 계산합니다...\")\n",
        "predictor_names = predictors_final.bandNames().getInfo()\n",
        "# training_df에는 환경 변수, pa, 좌표가 모두 포함\n",
        "mean_values = training_df[predictor_names].mean()\n",
        "print(\"계산 완료.\")\n",
        "\n",
        "# 그래프를 그릴 Matplotlib subplot 설정\n",
        "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
        "axes = axes.flatten() # 2x3 행렬을 1차원 배열로 만듬\n",
        "fig.suptitle('Response Curves for Predictor Variables', fontsize=20)\n",
        "\n",
        "# 각 변수에 대해 반복하며 반응 곡선 데이터 생성 및 시각화\n",
        "print(\"\\n각 변수별 반응 곡선을 생성합니다...\")\n",
        "\n",
        "for i, var_to_plot in enumerate(predictor_names):\n",
        "\n",
        "    # a. 해당 변수의 값 범위를 100단계로 나눔 (그래프의 x축)\n",
        "    min_val = training_df[var_to_plot].min()\n",
        "    max_val = training_df[var_to_plot].max()\n",
        "    value_range = np.linspace(min_val, max_val, 100)\n",
        "\n",
        "    # b. GEE에 보낼 테스트 데이터 생성\n",
        "    features_to_classify = []\n",
        "    for val in value_range:\n",
        "        # 평균값 딕셔너리를 복사하여 테스트 케이스 생성\n",
        "        properties = mean_values.to_dict()\n",
        "        # 현재 변수의 값만 루프의 값으로 변경\n",
        "        properties[var_to_plot] = val\n",
        "        # 지오메트리 없이 속성만 있는 Feature 생성\n",
        "        features_to_classify.append(ee.Feature(None, properties))\n",
        "\n",
        "    # c. GEE FeatureCollection으로 변환\n",
        "    fc_to_classify = ee.FeatureCollection(features_to_classify)\n",
        "\n",
        "    # d. 최종 모델로 예측 수행\n",
        "    classified_fc = fc_to_classify.classify(final_model, 'probability')\n",
        "\n",
        "    # e. 결과(확률 값)를 가져옴 (그래프의 y축)\n",
        "    predictions = classified_fc.aggregate_array('probability').getInfo()\n",
        "\n",
        "    # f. 해당 변수에 대한 그래프 그리기\n",
        "    ax = axes[i]\n",
        "    ax.plot(value_range, predictions, lw=2)\n",
        "    ax.set_xlabel(var_to_plot, fontsize=12)\n",
        "    ax.set_ylabel('Habitat Suitability', fontsize=12)\n",
        "    ax.set_title(f'Response to {var_to_plot}', fontsize=14)\n",
        "    ax.grid(True)\n",
        "\n",
        "# 사용되지 않는 subplot은 숨김\n",
        "for i in range(len(predictor_names), len(axes)):\n",
        "    fig.delaxes(axes[i])\n",
        "\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "plt.show()\n",
        "print(\"\\n반응 곡선 생성 완료.\")"
      ],
      "metadata": {
        "id": "EY1wT9HcPX0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8. 예측 지도 생성"
      ],
      "metadata": {
        "id": "5NuXfK_ltuf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 최적의 하이퍼파라미터로 최종 모델을 생성\n",
        "print(\"훈련된 최종 모델을 사용하여 서식지 적합성 지도를 생성합니다...\")\n",
        "suitability_map = predictors_final.classify(final_model)\n",
        "print(\"지도 생성 완료.\")\n",
        "\n",
        "# 예측 결과 시각화 준비\n",
        "# Viridis 색상 팔레트 (낮음: 보라색, 높음: 노란색)\n",
        "vis_params = {\n",
        "    'min': 0,\n",
        "    'max': 1,\n",
        "    'palette': ['#440154', '#482677', '#404788', '#33638D',\n",
        "                '#287D8E', '#1F968B', '#29AF7F', '#55C667',\n",
        "                '#95D840', '#DCE319']\n",
        "}\n",
        "\n",
        "# 지도 객체 생성 및 레이어 추가\n",
        "print(\"결과를 시각화합니다...\")\n",
        "m = geemap.Map(center=[36.54, 127.83], zoom=11)\n",
        "m.add_basemap('HYBRID')\n",
        "\n",
        "# 서식지 적합성 지도 레이어 추가\n",
        "m.addLayer(\n",
        "    suitability_map.select('probability'),\n",
        "    vis_params,\n",
        "    'Habitat Suitability'\n",
        ")\n",
        "# 지도에 컬러바 범례 추가\n",
        "m.add_colorbar(\n",
        "    vis_params,\n",
        "    label=\"Habitat Suitability\",\n",
        "    orientation=\"vertical\",\n",
        "    layer_name=\"Habitat Suitability\"\n",
        ")\n",
        "\n",
        "# 속리산 국립공원 경계 레이어 추가\n",
        "songnisan_park_boundary = ee.Image().paint(songnisan_park, 0, 2) # 경계선만 추출\n",
        "m.addLayer(\n",
        "    songnisan_park_boundary,\n",
        "    {'palette': 'black'},\n",
        "    'Songnisan Park Boundary'\n",
        ")\n",
        "\n",
        "# 출현 지점 레이어 추가\n",
        "m.addLayer(\n",
        "    presence_fc,\n",
        "    {'color': 'red'},\n",
        "    'Presence Points'\n",
        ")\n",
        "\n",
        "# 레이어 컨트롤 추가 및 최종 지도 출력\n",
        "m.add_layer_control()\n",
        "display(m)"
      ],
      "metadata": {
        "id": "zQCu1reetrvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이전 단계에서 계산된 'optimal_threshold' 변수를 사용\n",
        "print(f\"이전 단계에서 계산된 최적 임계값({optimal_threshold:.4f})을 사용하여 이진 지도를 생성합니다.\")\n",
        "\n",
        "# 이진(Binary) 잠재 분포 지도 생성\n",
        "potential_distribution_map = suitability_map.select('probability').gt(optimal_threshold)\n",
        "\n",
        "# 최종 지도 시각화\n",
        "print(\"잠재 분포 지도를 시각화합니다...\")\n",
        "binary_vis_params = {'min': 0, 'max': 1, 'palette': ['#D3D3D3', '#006400']} # 비서식지, 서식지\n",
        "\n",
        "m = geemap.Map(center=[36.54, 127.83], zoom=11)\n",
        "m.add_basemap('HYBRID')\n",
        "\n",
        "# 잠재 분포 지도 레이어 추가\n",
        "m.addLayer(potential_distribution_map, binary_vis_params, 'Potential Distribution (Binary)')\n",
        "\n",
        "# 국립공원 경계 레이어 추가\n",
        "park_boundary = ee.Image().paint(songnisan_park, 0, 2)\n",
        "m.addLayer(park_boundary, {'palette': 'black'}, 'Songnisan Park Boundary')\n",
        "\n",
        "# 출현 지점 레이어 추가\n",
        "m.addLayer(presence_fc, {'color': 'red'}, 'Presence Points')\n",
        "\n",
        "# 범례 추가\n",
        "m.add_legend(\n",
        "    title=\"Distribution\",\n",
        "    legend_dict={\"Suitable Habitat\": \"006400\", \"Unsuitable Habitat\": \"D3D3D3\"},\n",
        "    position=\"bottomright\"\n",
        ")\n",
        "\n",
        "m.add_layer_control()\n",
        "display(m)"
      ],
      "metadata": {
        "id": "wRQevDRmvJ1Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}